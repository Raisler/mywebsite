


[{"content":"","date":"28 de novembro de 2025","externalUrl":null,"permalink":"/tags/automa%C3%A7%C3%A3o/","section":"Tags","summary":"","title":"Automa√ß√£o","type":"tags"},{"content":" üé• Tutorial: Criando Clipes Virais de V√≠deos Longos com Python e IA # Este tutorial mostra como automatizar a cria√ß√£o de v√≠deos curtos verticais (Shorts, Reels, TikToks) a partir de um v√≠deo longo (MP4). Usaremos o AssemblyAI para transcrever o √°udio e o Gemini para identificar os melhores momentos para cortes.\nPr√©-requisitos: Voc√™ deve ter o FFmpeg instalado no seu sistema e as bibliotecas Python listadas abaixo.\n1. Configura√ß√£o e Bibliotecas üõ†Ô∏è # Primeiro, instalamos e importamos as bibliotecas necess√°rias para manipula√ß√£o de arquivos, chamadas de API e processamento de v√≠deo.\n1.1. Depend√™ncias # pip install google-genai requests 1.2. Importa√ß√£o de Bibliotecas # import subprocess # Executar comandos FFmpeg import json # Manipular respostas JSON import os # Lidar com o sistema de arquivos import requests # Fazer chamadas de API (AssemblyAI) import time # Atrasos para polling da API from google import genai # Acessar a API do Gemini from datetime import timedelta # Calcular tempos de legenda (SRT) import re # Sanitizar nomes de arquivos 2. Chaves e Vari√°veis de Projeto üîë # Insira suas chaves de API e defina o caminho para o seu arquivo de v√≠deo e o nome do projeto.\nASSEMBLY_API_KEY = \u0026#34;insira aqui\u0026#34; # Sua chave da AssemblyAI GEMINI_API = \u0026#34;insira aqui\u0026#34; # Sua chave da Google Gemini video_path = \u0026#34;IA_Atila.mp4\u0026#34; # O v√≠deo que ser√° cortado project_name = \u0026#34;IA_Atila\u0026#34; # Nome da pasta de sa√≠da para os clipes 3. Fun√ß√µes Essenciais ‚öôÔ∏è # 3.1. run_command (FFmpeg Helper) # Os v√≠deos ser√£o editados via terminal, o que eu particularmente acho bem legal, abaixo uma fun√ß√£o simples para executar comandos de terminal, como o FFmpeg, e monitorar seu sucesso ou erro.\ndef run_command(command): try: # Run the command and wait for it to finish result = subprocess.run(command, shell=True, text=True, capture_output=True) # Print the command\u0026#39;s output and errors print(\u0026#34;STDOUT:\\n\u0026#34;, result.stdout) print(\u0026#34;STDERR:\\n\u0026#34;, result.stderr) # Check if command was successful if result.returncode == 0: print(\u0026#34;Command executed successfully.\u0026#34;) else: print(f\u0026#34;Command failed with return code {result.returncode}\u0026#34;) except Exception as e: print(f\u0026#34;An error occurred: {e}\u0026#34;) 3.2. extract_audio (Convers√£o de V√≠deo) # Converte o arquivo de v√≠deo (.mp4) para um arquivo de √°udio (.mp3) usando FFmpeg. O √°udio √© necess√°rio para a transcri√ß√£o.\ndef extract_audio(input_path, output_path): # Usa FFmpeg para extrair a faixa de √°udio do v√≠deo e salva como MP3. ffmpeg_command = f\u0026#39;ffmpeg -i \u0026#34;{input_path}\u0026#34; -map a -c:a libmp3lame -b:a 192k \u0026#34;{output_path}\u0026#34;\u0026#39; run_command(ffmpeg_command) 3.3. Fun√ß√µes AssemblyAI (Transcri√ß√µes) üìù # Por qu√™ AssemblyAI? alguns modelos (os melhores) ocupam muito recurso da sua m√°quina e este √© uma api simples que custa apenas alguns centavos, sem falar que √© o melhor modelo de transcri√ß√£o que conhe√ßo. Conjunto de fun√ß√µes (upload_file, request_transcript, poll_transcript, transcribe_file) para enviar o arquivo de √°udio para o AssemblyAI e obter a transcri√ß√£o completa.\nDestaque: O config √© crucial, pois ativa o speaker_labels (r√≥tulos de locutor) e obt√©m dados detalhados para o subt√≠tulo no formato granular (palavra por palavra).\nconfig = { \u0026#34;speaker_labels\u0026#34;: True, # Essencial para identificar locutores \u0026#34;format_text\u0026#34;: True, # Formata√ß√£o de texto \u0026#34;punctuate\u0026#34;: True, # Pontua√ß√£o # ... outras configura√ß√µes ... } BASE_URL = \u0026#34;https://api.assemblyai.com\u0026#34; HEADERS = { \u0026#34;authorization\u0026#34;: ASSEMBLY_API_KEY, \u0026#34;content-type\u0026#34;: \u0026#34;application/json\u0026#34; } def upload_file(filepath): \u0026#34;\u0026#34;\u0026#34;Uploads a local file to AssemblyAI and returns the upload URL.\u0026#34;\u0026#34;\u0026#34; upload_endpoint = f\u0026#34;{BASE_URL}/v2/upload\u0026#34; headers = { \u0026#34;authorization\u0026#34;: ASSEMBLY_API_KEY, \u0026#34;content-type\u0026#34;: \u0026#34;application/octet-stream\u0026#34; } with open(filepath, \u0026#34;rb\u0026#34;) as f: response = requests.post(upload_endpoint, headers=headers, data=f) response.raise_for_status() upload_url = response.json()[\u0026#34;upload_url\u0026#34;] return upload_url def request_transcript(audio_url, config=None): \u0026#34;\u0026#34;\u0026#34;Requests a transcript for the given audio URL, returns the transcript ID.\u0026#34;\u0026#34;\u0026#34; transcript_endpoint = f\u0026#34;{BASE_URL}/v2/transcript\u0026#34; body = {\u0026#34;audio_url\u0026#34;: audio_url} if config: body.update(config) response = requests.post(transcript_endpoint, json=body, headers=HEADERS) response.raise_for_status() return response.json()[\u0026#34;id\u0026#34;] def poll_transcript(transcript_id, interval=3): \u0026#34;\u0026#34;\u0026#34;Polls the transcript endpoint until completed or error, then returns result.\u0026#34;\u0026#34;\u0026#34; polling_endpoint = f\u0026#34;{BASE_URL}/v2/transcript/{transcript_id}\u0026#34; while True: resp = requests.get(polling_endpoint, headers=HEADERS) resp.raise_for_status() result = resp.json() status = result[\u0026#34;status\u0026#34;] if status == \u0026#34;completed\u0026#34;: return result elif status == \u0026#34;error\u0026#34;: raise RuntimeError(f\u0026#34;Transcription failed: {result.get(\u0026#39;error\u0026#39;)}\u0026#34;) else: time.sleep(interval) config = { \u0026#34;speaker_labels\u0026#34;: True, \u0026#34;format_text\u0026#34;: True, \u0026#34;punctuate\u0026#34;: True, \u0026#34;speech_model\u0026#34;: \u0026#34;universal\u0026#34;, \u0026#34;language_detection\u0026#34;: True } def transcribe_file(filepath, config=config): \u0026#34;\u0026#34;\u0026#34;Uploads a file, requests its transcription, and returns the transcript result.\u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Uploading file...\u0026#34;) upload_url = upload_file(filepath) print(\u0026#34;Uploaded. URL:\u0026#34;, upload_url) print(\u0026#34;Requesting transcription...\u0026#34;) transcript_id = request_transcript(upload_url, config=config) print(\u0026#34;Polling for result (ID:\u0026#34;, transcript_id, \u0026#34;) ...\u0026#34;) transcript_result = poll_transcript(transcript_id) return transcript_result 3.4. prompt_task_definition (Instru√ß√µes para o Gemini) üß† # Esta string multi-linha cont√©m as instru√ß√µes detalhadas (o \u0026ldquo;prompt\u0026rdquo;) para o modelo Gemini. Ele define a fun√ß√£o da IA como um \u0026ldquo;Extrator de Subt√≥picos Virais\u0026rdquo; e exige que a sa√≠da seja um objeto JSON estruturado, voc√™ pode criar o seu prompt, mas acho que este meu promp √© bem eficiente. Com a pr√≥xima fun√ß√£o ser√° mandado a transcri√ß√£o em formato TOON para economizar tokens.\nprompt_task_definition = \u0026#34;\u0026#34;\u0026#34; # Extrator de Subt√≥picos Virais do YouTube Voc√™ √© um produtor de conte√∫do viral de elite com habilidades excepcionais na an√°lise de transcri√ß√µes do YouTube para identificar subt√≥picos de alto engajamento para reutiliza√ß√£o. Sua especialidade reside em reconhecer momentos com potencial viral que podem ser extra√≠dos para conte√∫do curto e independente. ## Seu Processo de An√°lise: 1. **Reconhecimento de Conte√∫do**: Identifique momentos emocionalmente ressonantes, revela√ß√µes surpreendentes, dicas pr√°ticas, insights contraintuitivos e destaques da narrativa. 2. **Conex√£o com o P√∫blico**: Concentre-se em segmentos que criem fortes rea√ß√µes emocionais (assombro, surpresa, humor, inspira√ß√£o) ou que ofere√ßam alto valor pr√°tico. 3. **An√°lise de Engajamento**: Priorize segmentos com ganchos claros, cita√ß√µes memor√°veis, din√¢micas de conflito/resolu√ß√£o ou momentos importantes. 4. **Avalia√ß√£o de Compartilhamento**: Avalie quais subt√≥picos t√™m maior probabilidade de incentivar os espectadores a compartilhar com outras pessoas. ## Seus Resultados: Para cada transcri√ß√£o fornecida, extraia de 3 a 8 subt√≥picos com alto potencial viral no formato JSON com a seguinte estrutura: ```json { \u0026#34;original_video\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;T√≠tulo original do v√≠deo do YouTube\u0026#34;, \u0026#34;summary\u0026#34;: \u0026#34;Breve resumo de 1 a 2 frases do conte√∫do completo\u0026#34; }, \u0026#34;viral_segments\u0026#34;: [ { \u0026#34;clip_title\u0026#34;: \u0026#34;T√≠tulo chamativo para este segmento\u0026#34;, \u0026#34;hook\u0026#34;: \u0026#34;O gancho de 1 frase que torna este clipe compartilh√°vel\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Breve descri√ß√£o explicando por que este segmento tem potencial viral\u0026#34;, \u0026#34;content_category\u0026#34;: [\u0026#34;Tutorial\u0026#34;, \u0026#34;Rea√ß√£o\u0026#34;, \u0026#34;Hist√≥ria\u0026#34;, \u0026#34;Conselho\u0026#34;, \u0026#34;Humor\u0026#34;, etc.], \u0026#34;index_range\u0026#34;: \u0026#34;h√° ind√≠ces (contagem de falas entre os locutores) no transcript, retorne o intervalo, por exemplo: 0-5\u0026#34; } ] } 3.5. create_prompt (Formata√ß√£o da Transcri√ß√£o) # Esta fun√ß√£o recebe a transcri√ß√£o bruta do AssemblyAI e a formata em um formato leg√≠vel e estruturado (chamado TOON - Token-Oriented Object Notation) para ser anexado ao prompt_task_definition. Isso garante que o Gemini possa analisar a transcri√ß√£o de forma eficaz, incluindo os √≠ndices de falas necess√°rios.\ndef create_prompt(data, prompt_task_definition): count = 0 output_toon = f\u0026#34;index_range[{len(data[\u0026#34;utterances\u0026#34;])}] {{List_index, Speaker, Text, start_time_ms, end_time_ms}}: \\n\u0026#34; for i in data[\u0026#34;utterances\u0026#34;]: entry = f\u0026#39;{count},\u0026#34;{i[\u0026#34;speaker\u0026#34;]}\u0026#34;,\u0026#34;{i[\u0026#34;text\u0026#34;]}\u0026#34;,{i[\u0026#34;start\u0026#34;]},{i[\u0026#34;end\u0026#34;]} \\n\u0026#39; output_toon += entry count += 1 prompt = prompt_task_definition + output_toon return prompt 3.6. get_viral_segments (Chamada ao Gemini) # Envia o prompt formatado para o modelo Gemini 2.5 Flash. O modelo analisa a transcri√ß√£o e retorna os segmentos virais identificados no formato JSON solicitado.\ndef get_viral_segments(prompt): client = genai.Client(api_key=GEMINI_API) response = client.models.generate_content( model=\u0026#34;gemini-2.5-flash\u0026#34;, contents=prompt, ) # RETURN AS JSON result = json.loads(response.text[7:-3]) return result 3.7. create_srt_from_words (Gera√ß√£o de Legendas) üí¨ # Uma fun√ß√£o crucial para criar um arquivo de legenda SRT (SubRip Subtitle) no formato granular, quebrando o texto em pequenas legendas (m√°x. 10 palavras ou 5 segundos), por√©m a fun√ß√£o permite voc√™ editar o tamanho de quantas palavras por momento.\nPonto-chave: Esta fun√ß√£o recebe um par√¢metro clip_start_offset_ms que subtrai o tempo de in√≠cio do corte de todos os timestamps das legendas. Isso garante que a legenda do clipe comece em 00:00:00,000, o que √© necess√°rio para o corte de v√≠deo posterior.\ndef create_srt_from_words( transcription_data, output_filename, # ... par√¢metros de quebra (max_words, max_duration_ms, etc.) clip_start_offset_ms=0 # \u0026lt;--- Subtrai o tempo de in√≠cio para \u0026#39;zerar\u0026#39; o SRT ): # ... c√≥digo da fun√ß√£o ... pass 3.8. create_vertical_clip (Corte e Edi√ß√£o de V√≠deo) ‚úÇÔ∏è # Usa FFmpeg para cortar o v√≠deo e transform√°-lo em um clipe vertical (formato 9:16).\ndef create_vertical_clip(input_file, output_file, subtitle_file, start_ms, end_ms): # Converte os milissegundos (ms) de Gemini/AssemblyAI para segundos (s) para o FFmpeg start_seconds = str(start_ms / 1000) end_seconds = str(end_ms / 1000) filter_graph = f\u0026#34;crop=ih*9/16:ih,subtitles={subtitle_file}\u0026#34; # Corta para 9:16 e aplica a legenda command = [ \u0026#34;ffmpeg\u0026#34;, # ... -ss (in√≠cio), -to (fim), -i (entrada), -vf (filtro), -c:a (codec de √°udio), (sa√≠da) ] # Executa o FFmpeg para criar o clipe # ... c√≥digo da fun√ß√£o ... 4. O Fluxo de Trabalho Final üöÄ # Extrai o √°udio do v√≠deo (extract_audio). Gera a transcri√ß√£o completa do √°udio (transcribe_file). Cria o prompt com as instru√ß√µes e a transcri√ß√£o formatada (create_prompt). Obt√©m os segmentos virais do Gemini (get_viral_segments). Para cada segmento viral: Extrai os tempos de in√≠cio e fim da transcri√ß√£o. Gera o arquivo SRT com os tempos \u0026ldquo;zerados\u0026rdquo; para o clipe (create_srt_from_words). Corta o v√≠deo original, aplica o filtro vertical e a legenda, gerando o clipe final (create_vertical_clip). video_name = video_path.split(\u0026#34;.\u0026#34;)[0] audio_path = f\u0026#34;{video_name}.mp3\u0026#34; os.makedirs(f\u0026#34;./{project_name}\u0026#34;, exist_ok=True) os.makedirs(f\u0026#34;./{project_name}/subtitles_\u0026#34;, exist_ok=True) extract_audio(video_path, audio_path) 5. Execu√ß√£o # # Garante que as pastas de sa√≠da existam video_name = video_path.split(\u0026#34;.\u0026#34;)[0] audio_path = f\u0026#34;{video_name}.mp3\u0026#34; os.makedirs(f\u0026#34;./{project_name}\u0026#34;, exist_ok=True) os.makedirs(f\u0026#34;./{project_name}/subtitles_\u0026#34;, exist_ok=True) # Inicia o processo de extra√ß√£o e transcri√ß√£o print(\u0026#34;extracting audio\u0026#34;) extract_audio(video_path, audio_path) # ... Segue com o resto das chamadas de API e cria√ß√£o de v√≠deos Este processo transforma um √∫nico arquivo de v√≠deo longo em v√°rios clipes curtos verticais, prontos para serem publicados, tudo de forma autom√°tica.\n","date":"28 de novembro de 2025","externalUrl":null,"permalink":"/tutorials/autoclips_tutorial_1/","section":"Tutoriais","summary":"","title":"Automatizando cria√ß√£o de v√≠deos curtos #1","type":"tutorials"},{"content":"","date":"28 de novembro de 2025","externalUrl":null,"permalink":"/categories/banco-de-dados/","section":"Categories","summary":"","title":"Banco De Dados","type":"categories"},{"content":"","date":"28 de novembro de 2025","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"28 de novembro de 2025","externalUrl":null,"permalink":"/tags/ia-generativa/","section":"Tags","summary":"","title":"IA Generativa","type":"tags"},{"content":"","date":"28 de novembro de 2025","externalUrl":null,"permalink":"/tags/llm/","section":"Tags","summary":"","title":"LLM","type":"tags"},{"content":"","date":"28 de novembro de 2025","externalUrl":null,"permalink":"/","section":"Meu Portf√≥lio","summary":"","title":"Meu Portf√≥lio","type":"page"},{"content":"","date":"28 de novembro de 2025","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"Bem-vindo √† se√ß√£o de Tutoriais.\n","date":"28 de novembro de 2025","externalUrl":null,"permalink":"/tutorials/","section":"Tutoriais","summary":"","title":"Tutoriais","type":"tutorials"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"Bem-vindo √† se√ß√£o de Projetos.\n","externalUrl":null,"permalink":"/projects/","section":"Projetos","summary":"","title":"Projetos","type":"projects"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]